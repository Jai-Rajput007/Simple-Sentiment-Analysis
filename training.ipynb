{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import re\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading IMDB dataset...\n",
      "Loading Amazon Polarity dataset...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1) Load datasets: IMDB (movie reviews) and Amazon Polarity (product reviews)\n",
    "print(\"Loading IMDB dataset...\")\n",
    "imdb_dataset = load_dataset(\"imdb\")\n",
    "print(\"Loading Amazon Polarity dataset...\")\n",
    "amazon_dataset = load_dataset(\"amazon_polarity\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert to DataFrames\n",
    "imdb_train_df = pd.DataFrame({'text': imdb_dataset['train']['text'], 'label': imdb_dataset['train']['label']})\n",
    "imdb_test_df = pd.DataFrame({'text': imdb_dataset['test']['text'], 'label': imdb_dataset['test']['label']})\n",
    "\n",
    "amazon_train_df = pd.DataFrame({'text': amazon_dataset['train']['content'], 'label': amazon_dataset['train']['label']})\n",
    "amazon_test_df = pd.DataFrame({'text': amazon_dataset['test']['content'], 'label': amazon_dataset['test']['label']})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combining datasets...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Combine the datasets (smaller subset for 8GB RAM)\n",
    "print(\"Combining datasets...\")\n",
    "train_df = pd.concat([\n",
    "    imdb_train_df.sample(2500, random_state=42),  # Subset of 2,500 IMDB reviews\n",
    "    amazon_train_df.sample(2500, random_state=42)  # Subset of 2,500 Amazon reviews\n",
    "], ignore_index=True)\n",
    "\n",
    "test_df = pd.concat([\n",
    "    imdb_test_df.sample(1000, random_state=42),  # Subset of 1,000 IMDB reviews\n",
    "    amazon_test_df.sample(1000, random_state=42)  # Subset of 1,000 Amazon reviews\n",
    "], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GloVe embeddings...\n",
      "Loaded 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2) Load pre-trained GloVe embeddings\n",
    "print(\"Loading GloVe embeddings...\")\n",
    "embedding_dim = 300  # Using 300-dimensional GloVe embeddings\n",
    "embeddings_index = {}\n",
    "with open('glove.6B.300d.txt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "print(f\"Loaded {len(embeddings_index)} word vectors.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3) Function to preprocess text and convert to embeddings\n",
    "def text_to_embedding(text, embeddings_index, embedding_dim):\n",
    "    # Simple preprocessing: lowercase, remove punctuation, split into words\n",
    "    text = re.sub(r'[^\\w\\s]', '', text.lower())\n",
    "    words = text.split()\n",
    "    \n",
    "    # Get embeddings for each word and average them\n",
    "    embeddings = []\n",
    "    for word in words:\n",
    "        if word in embeddings_index:\n",
    "            embeddings.append(embeddings_index[word])\n",
    "    \n",
    "    # If no words found in embeddings, return a zero vector\n",
    "    if not embeddings:\n",
    "        return np.zeros(embedding_dim)\n",
    "    \n",
    "    # Average the embeddings\n",
    "    embeddings = np.array(embeddings)\n",
    "    return np.mean(embeddings, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting training texts to embeddings...\n",
      "Converting test texts to embeddings...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 4) Convert all texts to embeddings\n",
    "print(\"Converting training texts to embeddings...\")\n",
    "X_train = np.array([text_to_embedding(text, embeddings_index, embedding_dim) for text in train_df['text']])\n",
    "y_train = train_df['label'].values\n",
    "\n",
    "print(\"Converting test texts to embeddings...\")\n",
    "X_test = np.array([text_to_embedding(text, embeddings_index, embedding_dim) for text in test_df['text']])\n",
    "y_test = test_df['label'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 5) Define a simple neural network for sentiment classification\n",
    "class SentimentClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(SentimentClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 6) Train the model\n",
    "input_dim = embedding_dim  # 300 (from GloVe embeddings)\n",
    "hidden_dim = 128  # Smaller hidden layer\n",
    "model = SentimentClassifier(input_dim, hidden_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Epoch 1/10, Loss: 0.5277, Test Accuracy: 0.6970\n",
      "Epoch 2/10, Loss: 0.4572, Test Accuracy: 0.7400\n",
      "Epoch 3/10, Loss: 0.3987, Test Accuracy: 0.7705\n",
      "Epoch 4/10, Loss: 0.3435, Test Accuracy: 0.7795\n",
      "Epoch 5/10, Loss: 0.3011, Test Accuracy: 0.7820\n",
      "Epoch 6/10, Loss: 0.2686, Test Accuracy: 0.7870\n",
      "Epoch 7/10, Loss: 0.2424, Test Accuracy: 0.7865\n",
      "Epoch 8/10, Loss: 0.2210, Test Accuracy: 0.7880\n",
      "Epoch 9/10, Loss: 0.2025, Test Accuracy: 0.7895\n",
      "Epoch 10/10, Loss: 0.1872, Test Accuracy: 0.7910\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "batch_size = 64  # Smaller batch size to reduce memory usage\n",
    "print(\"Training the model...\")\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for i in range(0, len(X_train), batch_size):\n",
    "        batch_X = X_train_tensor[i:i+batch_size]\n",
    "        batch_y = y_train_tensor[i:i+batch_size]\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(X_test_tensor)\n",
    "        test_preds = (test_outputs >= 0.5).float()\n",
    "        accuracy = accuracy_score(y_test, test_preds.numpy())\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}, Test Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 7) Evaluate the model on the test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test_tensor)\n",
    "    test_preds = (test_outputs >= 0.5).float().numpy()\n",
    "    test_probs = test_outputs.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Test Set Metrics:\n",
      "Accuracy:  0.7910\n",
      "Precision: 0.8135\n",
      "Recall:    0.7513\n",
      "F1-score:  0.7812\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print performance metrics\n",
    "accuracy = accuracy_score(y_test, test_preds)\n",
    "precision = precision_score(y_test, test_preds)\n",
    "recall = recall_score(y_test, test_preds)\n",
    "f1 = f1_score(y_test, test_preds)\n",
    "print(\"\\nFinal Test Set Metrics:\")\n",
    "print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1-score:  {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 8) Function to predict sentiment on new text\n",
    "def predict_sentiment(text, model, embeddings_index, embedding_dim):\n",
    "    # Convert text to embedding\n",
    "    embedding = text_to_embedding(text, embeddings_index, embedding_dim)\n",
    "    embedding_tensor = torch.tensor(embedding, dtype=torch.float32).view(1, -1)\n",
    "    \n",
    "    # Predict sentiment\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(embedding_tensor)\n",
    "        prob = output.item()\n",
    "        pred = 1 if prob >= 0.5 else 0\n",
    "        sentiment = \"Positive\" if pred == 1 else \"Negative\"\n",
    "    return sentiment, prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'sentiment_classifier.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing the model on a variety of example texts:\n",
      "Text: I love this movie, it’s amazing!\n",
      "Sentiment: Positive, Probability: 0.9991\n",
      "\n",
      "Text: This phone is terrible, it keeps crashing.\n",
      "Sentiment: Negative, Probability: 0.0456\n",
      "\n",
      "Text: I had an amazing day at the park with my friends!\n",
      "Sentiment: Positive, Probability: 0.9977\n",
      "\n",
      "Text: The lecture was boring and unhelpful.\n",
      "Sentiment: Negative, Probability: 0.0012\n",
      "\n",
      "Text: I’m so excited for the weekend, it’s going to be great!\n",
      "Sentiment: Positive, Probability: 0.9856\n",
      "\n",
      "Text: The food at this restaurant was disappointing and overpriced.\n",
      "Sentiment: Negative, Probability: 0.0059\n",
      "\n",
      "Text: I really enjoyed the concert last night, the music was fantastic!\n",
      "Sentiment: Positive, Probability: 0.9981\n",
      "\n",
      "Text: My new laptop is super fast and easy to use.\n",
      "Sentiment: Positive, Probability: 0.9945\n",
      "\n",
      "Text: The weather today is awful, I hate this rain!\n",
      "Sentiment: Negative, Probability: 0.0684\n",
      "\n",
      "Text: I’m feeling so happy after talking to my best friend.\n",
      "Sentiment: Positive, Probability: 0.9760\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 9) Test on a variety of example texts\n",
    "example_texts = [\n",
    "    \"I love this movie, it’s amazing!\",  # Movie-related\n",
    "    \"This phone is terrible, it keeps crashing.\",  # Product review\n",
    "    \"I had an amazing day at the park with my friends!\",  # Casual talk\n",
    "    \"The lecture was boring and unhelpful.\",  # Feedback\n",
    "    \"I’m so excited for the weekend, it’s going to be great!\",  # Random thought\n",
    "    \"The food at this restaurant was disappointing and overpriced.\",  # Restaurant review\n",
    "    \"I really enjoyed the concert last night, the music was fantastic!\",  # Event\n",
    "    \"My new laptop is super fast and easy to use.\",  # Product review\n",
    "    \"The weather today is awful, I hate this rain!\",  # Weather\n",
    "    \"I’m feeling so happy after talking to my best friend.\"  # Emotion\n",
    "]\n",
    "\n",
    "print(\"\\nTesting the model on a variety of example texts:\")\n",
    "for text in example_texts:\n",
    "    sentiment, prob = predict_sentiment(text, model, embeddings_index, embedding_dim)\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Sentiment: {sentiment}, Probability: {prob:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your own text to predict its sentiment (or type 'exit' to stop):\n",
      "Sentiment: Positive, Probability: 0.9426\n",
      "Sentiment: Positive, Probability: 0.9426\n",
      "Sentiment: Positive, Probability: 0.9938\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 10) Interactive sentiment prediction\n",
    "print(\"Enter your own text to predict its sentiment (or type 'exit' to stop):\")\n",
    "while True:\n",
    "    text = input(\"Text: \")\n",
    "    if text.lower() == 'exit':\n",
    "        break\n",
    "    sentiment, prob = predict_sentiment(text, model, embeddings_index, embedding_dim)\n",
    "    print(f\"Sentiment: {sentiment}, Probability: {prob:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
